{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07574a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://5cbf7cf21bed:4040\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1674990521445)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.wololo.geojson.GeoJSONFactory\n",
       "import org.wololo.jts2geojson.GeoJSONReader\n",
       "import org.wololo.geojson.Feature\n",
       "import org.apache.spark.sql.DataFrame\n",
       "readGeojson: (filePath: String)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.wololo.geojson.GeoJSONFactory\n",
    "import org.wololo.jts2geojson.GeoJSONReader\n",
    "import org.wololo.geojson.Feature\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "def readLineOfGeojson(filePath: String): DataFrame = {\n",
    "    val colnames = Seq(\"TRIP_ID\", \"CALL_TYPE\", \"ORIGIN_STAND\", \"TAXI_ID\", \"TIMESTAMP\", \"DAY_TYPE\", \"MISSING_DATA\",  \"geometry\")\n",
    "    sc.textFile(filePath).map(line => {\n",
    "        val feature = GeoJSONFactory.create(line).asInstanceOf[Feature]\n",
    "        val reader = new GeoJSONReader\n",
    "        (\n",
    "            feature.getProperties.get(\"TRIP_ID\").asInstanceOf[Long]\n",
    "            ,feature.getProperties.get(\"CALL_TYPE\").asInstanceOf[String]\n",
    "            ,feature.getProperties.get(\"ORIGIN_STAND\").asInstanceOf[String]\n",
    "            ,feature.getProperties.get(\"TAXI_ID\").asInstanceOf[Integer]\n",
    "            ,feature.getProperties.get(\"TIMESTAMP\").asInstanceOf[String]\n",
    "            ,feature.getProperties.get(\"DAY_TYPE\").asInstanceOf[String]\n",
    "            ,feature.getProperties.get(\"MISSING_DATA\").asInstanceOf[Boolean]\n",
    "            ,reader.read(feature.getGeometry)\n",
    "        )\n",
    "    }).toDF(colnames: _*)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7f1482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+--------+--------------------+--------+------------+--------------------+\n",
      "|            TRIP_ID|CALL_TYPE|ORIGIN_STAND| TAXI_ID|           TIMESTAMP|DAY_TYPE|MISSING_DATA|            geometry|\n",
      "+-------------------+---------+------------+--------+--------------------+--------+------------+--------------------+\n",
      "|1373017604620000351|        C|            |20000351|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "|1373277091620000446|        C|            |20000446|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "|1373462211620000500|        C|            |20000500|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "|1374755673620000663|        C|            |20000663|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "|1375977626620000337|        C|            |20000337|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "|1375984752620000337|        C|            |20000337|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.4...|\n",
      "|1377074177620000351|        C|            |20000351|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "|1378983239620000138|        C|            |20000138|java.util.Gregori...|       A|       false|MULTIPOINT ((-14....|\n",
      "|1382058070620000089|        C|            |20000089|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "|1385030885620000018|        A|            |20000018|java.util.Gregori...|       A|       false|MULTIPOINT ((-17....|\n",
      "|1396631707620000163|        C|            |20000163|java.util.Gregori...|       A|        true|MULTIPOINT ((-10....|\n",
      "|1396852830620000675|        B|          62|20000675|java.util.Gregori...|       A|       false|MULTIPOINT ((-12....|\n",
      "|1401345507620000496|        C|            |20000496|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "|1403591995620000472|        C|            |20000472|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.7...|\n",
      "|1403959128620000295|        C|            |20000295|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.8...|\n",
      "|1380007556620000351|        C|            |20000351|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.0...|\n",
      "|1373724238620000680|        C|            |20000680|java.util.Gregori...|       A|       false|MULTIPOINT ((-7.9...|\n",
      "|1373367299620000351|        C|            |20000351|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "|1380005160620000351|        C|            |20000351|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "|1379510294620000351|        C|            |20000351|java.util.Gregori...|       A|       false|MULTIPOINT ((-8.6...|\n",
      "+-------------------+---------+------------+--------+--------------------+--------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "testFile: String = /home/iceberg/data/test_portotaxi.geojson\n",
       "df_test: org.apache.spark.sql.DataFrame = [TRIP_ID: bigint, CALL_TYPE: string ... 6 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val testFile = \"/home/iceberg/data/test_portotaxi.geojson\"\n",
    "val df_test = readLineOfGeojson(testFile)\n",
    "df_test.createOrReplaceTempView(\"test_portotaxi\")\n",
    "df_test.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e85caf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TRIP_ID: long (nullable = false)\n",
      " |-- CALL_TYPE: string (nullable = true)\n",
      " |-- ORIGIN_STAND: string (nullable = true)\n",
      " |-- TAXI_ID: integer (nullable = true)\n",
      " |-- TIMESTAMP: string (nullable = true)\n",
      " |-- DAY_TYPE: string (nullable = true)\n",
      " |-- MISSING_DATA: boolean (nullable = false)\n",
      " |-- geometry: geometry (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdebf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Long = 50\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM test_portotaxi\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f3b175",
   "metadata": {},
   "source": [
    "## 1. Create a iceberg table with geometry type\n",
    "\n",
    "\n",
    "The `write.parquet.geometry.encoding` has 3 possible values:\n",
    "\n",
    "- `nested-list`: the most efficient (usually have small file size, faster reading and writing)\n",
    "\n",
    "- `wkb-bbox`\n",
    "\n",
    "- `wkb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e0f5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS demo.db.test_portotaxi\")\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS demo.db.test_portotaxi \n",
    "(\n",
    "  TRIP_ID LONG,\n",
    "  CALL_TYPE STRING,\n",
    "  ORIGIN_STAND STRING,\n",
    "  TAXI_ID INTEGER,\n",
    "  TIMESTAMP STRING,\n",
    "  DAY_TYPE STRING,\n",
    "  MISSING_DATA BOOLEAN,\n",
    "  geometry GEOMETRY\n",
    ")\n",
    "USING iceberg\n",
    "TBLPROPERTIES ('write.parquet.geometry.encoding' = 'nested-list')\n",
    "\"\"\")\n",
    "          \n",
    "spark.sql(\"INSERT INTO demo.db.test_portotaxi SELECT * FROM test_portotaxi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d3b63",
   "metadata": {},
   "source": [
    "## 2. Table Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ce09e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|total_records|    file_size_in_mb|\n",
      "+-------------+-------------------+\n",
      "|           50|0.13652706146240234|\n",
      "+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT\n",
    "    summary['total-records'] as total_records,\n",
    "    summary['total-files-size'] / 1024 / 1024 as file_size_in_mb \n",
    "    FROM demo.db.test_portotaxi.snapshots\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc5c202",
   "metadata": {},
   "source": [
    "## 3. Run Spatial Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ef94e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bbox: String = POLYGON ((-8.6079 41.1489, -8.6089 41.1472, -8.6066 41.1470, -8.6061 41.1483, -8.6079 41.1489))\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bbox = \"POLYGON ((-8.6079 41.1489, -8.6089 41.1472, -8.6066 41.1470, -8.6061 41.1483, -8.6079 41.1489))\"\n",
    "spark.sql(s\"\"\"\n",
    "SELECT count(*)\n",
    "FROM demo.db.test_portotaxi\n",
    "WHERE ST_Within(geometry, ST_GeomFromText('${bbox}'))\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
